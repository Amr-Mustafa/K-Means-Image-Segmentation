# -*- coding: utf-8 -*-
"""ImageSegmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sxuxIUq1WlEQ9PNsTcq85MJcSmYnqho3
"""

# Dependencies.
import tarfile
import urllib.request
import os
from PIL import Image
import numpy as np
from scipy.io import loadmat
import matplotlib.pyplot as plt
import matplotlib
from collections import defaultdict 
from sklearn.metrics import f1_score, precision_score
import cv2 as cv
from sklearn.cluster import SpectralClustering
from sklearn.feature_extraction import image
import scipy

"""# **1. The BSR Dataset**
The new Berkeley Segmentation Data Set and Benchmarks 500 (BSDS500) is an extension of the BSDS300, where the original 300 images are used for training / validation and 200 fresh images, together with human annotations, are added for testing. Each image was segmented by five different subjects on average.

To obtain the dataset, we download the tar ball over the network and extract it in the runtime environment instead of mounting the drive. We then prepare the absolute paths to the data we require for the project.
"""

tar_path = "http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz"
http_stream = urllib.request.urlopen(tar_path)
tar_file = tarfile.open(fileobj=http_stream, mode="r|gz")
tar_file.extractall()

images_path = "/content/BSR/BSDS500/data/images"
ground_truth_path = "/content/BSR/BSDS500/data/groundTruth"

"""# **2. The Data Matrix**
Our data matrix $D$ is organized as a 3-dimensional matrix with each dimension or channel being a $154401\times200$ matrix. Three channels are required because our images are RGB-colored images, thus we need a distinct channel for each of the three base colors. Associated with each image are three 154401-dimensional vectors "overlayed" onto each other across the three channels.

<img align="center" src="https://imgbbb.com/images/2019/11/13/3D-matrix.png" />
"""

# Generate the training set.
D_train_X = np.empty([481*321, 200, 3])
dimensions = {}

# Choose the image to reconstruct later as a check.
debug_image = "3063"
debug_index = 0

i = 0
for filename in os.listdir(images_path + "/test"):
    if filename.endswith(".jpg"):

         # Get the index into the data matrix.
         if os.path.splitext(filename)[0] == debug_image:
           debug_index = i
         
         # Read the image and save its native dimensions for later use.
         img = Image.open(images_path + "/test/" + filename)
         dimensions[os.path.splitext(filename)[0]] = (img.width, img.height)

         # Split the image into the appropriate matrices and vectors.
         img_mat = np.array(img)
         img_mat_r, img_mat_g, img_mat_b = img_mat[:, :, 0], img_mat[:, :, 1], img_mat[:, :, 2]
         vec_r, vec_g, vec_b = img_mat_r.reshape(481*321), img_mat_g.reshape(481*321), img_mat_b.reshape(481*321)
         D_train_X[:, i, 0], D_train_X[:, i, 1], D_train_X[:, i, 2] = vec_r, vec_g, vec_b
         i += 1

# A quick sanity check to make sure we split the channels correctly.
# We simply reconstruct the last image from our data matrix.
w, h = dimensions[debug_image][0], dimensions[debug_image][1]
image_matrix = np.zeros((h, w, 3), dtype='uint8')
image_matrix[:, :, 0] = D_train_X[:, debug_index, 0].reshape(h, w)
image_matrix[:, :, 1] = D_train_X[:, debug_index, 1].reshape(h, w)
image_matrix[:, :, 2] = D_train_X[:, debug_index, 2].reshape(h, w)
reconstructed_image = Image.fromarray(image_matrix ,'RGB')
reconstructed_image

"""## **3. The Ground Truth**
On average, an image has 5 ground truth segmentations. In this section, we define a method to return the ground truth images associated with a given image and display them side by side.
"""

## Takes an image identifier and returns a list of its ground truth image(s).
## An optional parameter can be set to also display the image along with
## its ground truth image(s).
def ground_truth(image_name, display=False):
  ground_truth_list = []
  n_annot = 0

  for filename in os.listdir(ground_truth_path + "/test"):
    if filename.endswith(".mat") and os.path.splitext(filename)[0] == image_name:
      gt = loadmat(ground_truth_path + "/test/" + filename)['groundTruth'][0]
      n_annot = gt.shape[0]
      ground_truth_list = [gt[k]['Boundaries'][0][0] for k in range(n_annot)]

  if display:
    fig, axes = plt.subplots(1, n_annot+1, figsize=(20,7))
    fig.suptitle('An Example Image With Its Ground Truth Displayed')
    if n_annot > 0:
      axes[0].imshow(Image.open(images_path + "/test/" + image_name + ".jpg"))
    else:
      axes.imshow(Image.open(images_path + "/test/" + image_name + ".jpg"))
    for i, ax in enumerate(axes[1:]):
      ax.imshow(ground_truth_list[i], cmap='binary', interpolation='bessel')

  return ground_truth_list

gt = ground_truth(debug_image, True)

"""## **4. K-Means Segmentation**
K-means is a clustering algorithm that employs a greedy iterative approach to find a clustering that minimizes the sum of squared errors (SSE) objective function. The algorithm initializes the k cluster means by randomly generating k points in the data space. Each iteration of K-means consits of two steps:


1.   Clutser assignment.
2.   Centroid update.

<img src="https://i.ibb.co/PQ7vhVk/Capture.jpg">
"""

def kMeans(im, k, eps):
  
  m = np.array(im)
  w, h, n_ch = m.shape

  # Unroll the matrix into a vector.
  m = m.reshape(m.shape[0]*m.shape[1], 3)

  # Randomly initialize k means (or centroids).
  u = np.random.randint(0, 256, (1, k, 3))
  p = {}
  # Repeat until convergence.
  for i in range(20):#while True:

    # Cluster assignment step.
    c = defaultdict(list) ### k clusters.
    ## Get the nearest cluster for this pixel.
    d = [np.linalg.norm(m[j, :] - u[0][i])**2 for j in range(m.shape[0]) for i in range(k)]
    ## Assign each pixel to the closest centroid.
    indicator = [np.argmin(d[i:i+k]) for i in range(0, len(d), k)]
    for i in range(k): 
      for j in range(m.shape[0]):
        if indicator[j] == i:
          c[i].append(m[j, :])
          p[j] = i
    
    # Centroid update step.
    ## We calculate the centroid of each cluster.
    for i in range(k):
      if len(c[i]):
        u[0][i] = np.sum(c[i], axis=0) / len(c[i])

  return c, p

# Segmentation results for a single image.
im = Image.open(images_path + "/test/" + debug_image + ".jpg")

fig, axes = plt.subplots(1, 5, figsize=(20, 7))

clusters, p = kMeans(im, 3, 10)
seg1 = np.array([p[key] for key in sorted(p.keys())])
axes[0].imshow(seg1.reshape(im.height, im.width))

clusters, p = kMeans(im, 5, 10)
seg2 = np.array([p[key] for key in sorted(p.keys())])
axes[1].imshow(seg2.reshape(im.height, im.width))

clusters, p = kMeans(im, 7, 10)
seg3 = np.array([p[key] for key in sorted(p.keys())])
axes[2].imshow(seg3.reshape(im.height, im.width))

clusters, p = kMeans(im, 9, 10)
seg4 = np.array([p[key] for key in sorted(p.keys())])
axes[3].imshow(seg4.reshape(im.height, im.width))

clusters, p = kMeans(im, 11, 10)
seg5 = np.array([p[key] for key in sorted(p.keys())])

axes[4].imshow(seg5.reshape(im.height, im.width))

"""## **4. Evaluation**
In evaluating the clustering results, we will use the following measures:
1.   F-measure
2.   Conditional Entropy
"""

from scipy import ndimage
from sklearn.metrics.cluster import contingency_matrix

labeled, nr_objects = ndimage.label(np.logical_not(gt[0].reshape(im.height, im.width)))
fig, axes = plt.subplots(1,1, figsize=(20,7))
axes.imshow(labeled.reshape(im.height, im.width))

contingency_mat = contingency_matrix(labeled, seg1)
print(contingency_mat)

precision_score(gt[0].reshape(gt[0].shape[0] * gt[0].shape[1]), seg4, average='micro')

"""## **5. Big Picture and Normalized Cut**"""

def ncut(im):
  img = im.resize((int(0.2*im.width), int(0.2*im.height)))
  img = np.array(img)
  s = img.shape

  images = []
  images.append(np.ravel(img[:,:,0]))
  images.append(np.ravel(img[:,:,1]))
  images.append(np.ravel(img[:,:,2]))
  images = np.array(images)

  clustering = SpectralClustering(n_clusters=5, assign_labels="kmeans", random_state=0, affinity='nearest_neighbors', n_neighbors=5).fit(images.T)
  plt.imshow(clustering.labels_.reshape(s[0:2]))
  plt.show()

# Normalized Cut.
test_images=[2018,14085,15011,15062,16004]
for image in test_images:
  current = Image.open(images_path + "/test/" + str(image) + ".jpg")
  ncut(current)

# KMeans.
test_images=[2018,14085,15011,15062,16004]
fig, axes = plt.subplots(1, 5, figsize=(20,7))
for i, image in enumerate(test_images):
  current = Image.open(images_path + "/test/" + str(image) + ".jpg")
  clusters, p = kMeans(current, 5, 10)
  seg = np.array([p[key] for key in sorted(p.keys())])
  axes[i].imshow(seg.reshape(im.height, im.width), interpolation='nearest')

for i, image in enumerate(test_images):
  gt = ground_truth(str(image), True)